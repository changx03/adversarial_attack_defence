{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from aad.datasets import DATASET_LIST, DataContainer\n",
    "from aad.utils import get_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = 'Iris'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = DataContainer(DATASET_LIST[NAME], get_data_path())\n",
    "dc(shuffle=True, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = dc.x_train\n",
    "y_train = dc.y_train\n",
    "x_test = dc.x_test\n",
    "y_test = dc.y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "ExtraTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n                    max_depth=None, max_features='auto', max_leaf_nodes=None,\n                    min_impurity_decrease=0.0, min_impurity_split=None,\n                    min_samples_leaf=1, min_samples_split=2,\n                    min_weight_fraction_leaf=0.0, random_state=None,\n                    splitter='random')"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "classifier = ExtraTreeClassifier(\n",
    "    criterion='gini',\n",
    "    splitter='random',\n",
    ")\n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[ 0.05617823  0.00148903  0.36513569  0.57719706]\n"
    }
   ],
   "source": [
    "print(classifier.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(predictions, labels):\n",
    "    return np.sum(np.equal(predictions, labels)) / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy on test set: 0.9\n"
    }
   ],
   "source": [
    "accuracy = evaluate(pred, y_test)\n",
    "print(f'Accuracy on test set: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply decision tree attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.attacks import DecisionTreeAttack\n",
    "from art.classifiers import SklearnClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_classifier = SklearnClassifier(classifier)\n",
    "attack = DecisionTreeAttack(art_classifier)\n",
    "adv = attack.generate(x_test)\n",
    "pred_adv = classifier.predict(adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy on DecisionTreeAttack: 0.03333333333333333\n"
    }
   ],
   "source": [
    "accuracy = evaluate(pred_adv, y_test)\n",
    "print(f'Accuracy on DecisionTreeAttack: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Transferability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy on clean set: 1.0\n"
    }
   ],
   "source": [
    "attack_list = ['FGSM', 'BIM', 'DeepFool', 'Carlini']\n",
    "x = np.load(os.path.join('..', 'save', 'IrisNN_Iris_BIM_x.npy'), allow_pickle=False)\n",
    "y = np.load(os.path.join('..', 'save', 'IrisNN_Iris_BIM_y.npy'), allow_pickle=False)\n",
    "pred = classifier.predict(x)\n",
    "accuracy = evaluate(pred, y)\n",
    "print(f'Accuracy on clean set: {accuracy}')\n",
    "\n",
    "adv_files = []\n",
    "for adv_name in attack_list:\n",
    "    adv_files.append(f'IrisNN_Iris_{adv_name}_adv.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy on FGSM set: 0.38333333333333336\nAccuracy on BIM set: 0.03333333333333333\nAccuracy on DeepFool set: 0.43333333333333335\nAccuracy on Carlini set: 0.35\n"
    }
   ],
   "source": [
    "for i in range(len(attack_list)):\n",
    "    adv = np.load(os.path.join('..', 'save', adv_files[i]), allow_pickle=False)\n",
    "    pred = classifier.predict(adv)\n",
    "    accuracy = evaluate(pred, y)\n",
    "    print(f'Accuracy on {attack_list[i]} set: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applicability Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aad.basemodels import ModelContainerTree\n",
    "from aad.defences import ApplicabilityDomainContainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "mc = ModelContainerTree(classifier, dc)\n",
    "hidden_model = None\n",
    "ad = ApplicabilityDomainContainer(\n",
    "    mc,\n",
    "    mc.hidden_model,\n",
    "    k2=6,\n",
    "    reliability=1.0,\n",
    "    sample_ratio=1.0,\n",
    "    kappa=6,\n",
    "    confidence=0.8\n",
    ")\n",
    "ad.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Blocked 8/60 samples on Clean set\n"
    }
   ],
   "source": [
    "blocked_idx = ad.detect(x, y)\n",
    "print(f'Blocked {len(blocked_idx)}/{len(x)} samples on Clean set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(attack_list)):\n",
    "    adv = np.load(os.path.join('..', 'save', adv_files[i]), allow_pickle=False)\n",
    "    blocked_idx = ad.detect(adv)\n",
    "    print(f'Blocked {len(blocked_idx)}/{len(x)} samples on {attack_list[i]}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bitvenvvenv8dcf9344434f491ca199f1f4919d76d1",
   "display_name": "Python 3.6.9 64-bit ('venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}