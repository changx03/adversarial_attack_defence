{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from attacks import FGSMContainer\n",
    "from basemodels import TorchModelContainer, IrisNN\n",
    "from datasets import DATASET_LIST, DataContainer, get_dataset_list\n",
    "# from defences import DefenceContainer\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "3.6.9 (default, Nov  7 2019, 10:44:02) \n[GCC 8.3.0]\n/home/lukec/.vscode/extensions/ms-python.python-2020.2.64397/pythonFiles\n/home/lukec/.vscode/extensions/ms-python.python-2020.2.64397/pythonFiles/lib/python\n/usr/lib/python36.zip\n/usr/lib/python3.6\n/usr/lib/python3.6/lib-dynload\n\n/home/lukec/venv/lib/python3.6/site-packages\n/home/lukec/Downloads/jax/build\n/home/lukec/.local/lib/python3.6/site-packages\n/usr/local/lib/python3.6/dist-packages\n/usr/lib/python3/dist-packages\n/home/lukec/venv/lib/python3.6/site-packages/IPython/extensions\n/home/lukec/.ipython\n"
    }
   ],
   "source": [
    "print(sys.version)\n",
    "print(*sys.path, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Avaliable datasets:\n['MNIST', 'CIFAR10', 'SVHN', 'BankNote', 'BreastCancerWisconsin', 'HTRU2', 'Iris', 'WheatSeed']\n"
    }
   ],
   "source": [
    "print('Avaliable datasets:')\n",
    "print(get_dataset_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Starting Iris data container...\n{'name': 'Iris', 'type': 'quantitative', 'size': 150, 'num_classes': 3, 'dim_data': (4,)}\nLoading data...\nPreparing DataFrame...\nReading from data/iris.data\nSpliting train/test sets into numpy arrays...\nSuccessfully load data! Time taken:  0m 0.0s\nFeatures: 4\nClasses: 3\nUsing model: IrisNN\nUsing device: cuda:0\n{'lr': 0.01, 'momentum': 0.9}\n[ 1/50]  0m 0.0s - Train Loss: 1.0582 Acc: 57.5000% - Test Loss: 1.1009 Acc: 43.3333%\n[ 2/50]  0m 0.0s - Train Loss: 1.0561 Acc: 63.3333% - Test Loss: 1.0972 Acc: 53.3333%\n[ 3/50]  0m 0.0s - Train Loss: 1.0525 Acc: 66.6667% - Test Loss: 1.0923 Acc: 56.6667%\n[ 4/50]  0m 0.0s - Train Loss: 1.0474 Acc: 69.1667% - Test Loss: 1.0855 Acc: 56.6667%\n[ 5/50]  0m 0.0s - Train Loss: 1.0409 Acc: 69.1667% - Test Loss: 1.0777 Acc: 56.6667%\n[ 6/50]  0m 0.0s - Train Loss: 1.0334 Acc: 69.1667% - Test Loss: 1.0695 Acc: 56.6667%\n[ 7/50]  0m 0.0s - Train Loss: 1.0252 Acc: 69.1667% - Test Loss: 1.0612 Acc: 56.6667%\n[ 8/50]  0m 0.0s - Train Loss: 1.0166 Acc: 69.1667% - Test Loss: 1.0519 Acc: 56.6667%\n[ 9/50]  0m 0.0s - Train Loss: 1.0075 Acc: 69.1667% - Test Loss: 1.0429 Acc: 56.6667%\n[10/50]  0m 0.0s - Train Loss: 0.9980 Acc: 69.1667% - Test Loss: 1.0337 Acc: 56.6667%\n[11/50]  0m 0.0s - Train Loss: 0.9881 Acc: 69.1667% - Test Loss: 1.0243 Acc: 56.6667%\n[12/50]  0m 0.0s - Train Loss: 0.9776 Acc: 69.1667% - Test Loss: 1.0145 Acc: 56.6667%\n[13/50]  0m 0.0s - Train Loss: 0.9667 Acc: 69.1667% - Test Loss: 1.0044 Acc: 56.6667%\n[14/50]  0m 0.0s - Train Loss: 0.9553 Acc: 69.1667% - Test Loss: 0.9940 Acc: 56.6667%\n[15/50]  0m 0.0s - Train Loss: 0.9431 Acc: 69.1667% - Test Loss: 0.9831 Acc: 56.6667%\n[16/50]  0m 0.0s - Train Loss: 0.9300 Acc: 69.1667% - Test Loss: 0.9716 Acc: 56.6667%\n[17/50]  0m 0.0s - Train Loss: 0.9159 Acc: 69.1667% - Test Loss: 0.9593 Acc: 56.6667%\n[18/50]  0m 0.0s - Train Loss: 0.9007 Acc: 69.1667% - Test Loss: 0.9461 Acc: 56.6667%\n[19/50]  0m 0.0s - Train Loss: 0.8847 Acc: 69.1667% - Test Loss: 0.9322 Acc: 56.6667%\n[20/50]  0m 0.0s - Train Loss: 0.8672 Acc: 69.1667% - Test Loss: 0.9181 Acc: 56.6667%\n[21/50]  0m 0.0s - Train Loss: 0.8498 Acc: 69.1667% - Test Loss: 0.9040 Acc: 56.6667%\n[22/50]  0m 0.0s - Train Loss: 0.8299 Acc: 69.1667% - Test Loss: 0.8887 Acc: 56.6667%\n[23/50]  0m 0.0s - Train Loss: 0.8107 Acc: 69.1667% - Test Loss: 0.8732 Acc: 56.6667%\n[24/50]  0m 0.0s - Train Loss: 0.7903 Acc: 69.1667% - Test Loss: 0.8568 Acc: 56.6667%\n[25/50]  0m 0.0s - Train Loss: 0.7702 Acc: 69.1667% - Test Loss: 0.8403 Acc: 56.6667%\n[26/50]  0m 0.0s - Train Loss: 0.7493 Acc: 69.1667% - Test Loss: 0.8230 Acc: 56.6667%\n[27/50]  0m 0.0s - Train Loss: 0.7289 Acc: 69.1667% - Test Loss: 0.8057 Acc: 56.6667%\n[28/50]  0m 0.0s - Train Loss: 0.7076 Acc: 69.1667% - Test Loss: 0.7879 Acc: 56.6667%\n[29/50]  0m 0.0s - Train Loss: 0.6871 Acc: 69.1667% - Test Loss: 0.7701 Acc: 56.6667%\n[30/50]  0m 0.0s - Train Loss: 0.6670 Acc: 69.1667% - Test Loss: 0.7525 Acc: 56.6667%\n[31/50]  0m 0.0s - Train Loss: 0.6468 Acc: 69.1667% - Test Loss: 0.7353 Acc: 56.6667%\n[32/50]  0m 0.0s - Train Loss: 0.6275 Acc: 69.1667% - Test Loss: 0.7184 Acc: 56.6667%\n[33/50]  0m 0.0s - Train Loss: 0.6088 Acc: 69.1667% - Test Loss: 0.7022 Acc: 56.6667%\n[34/50]  0m 0.0s - Train Loss: 0.5912 Acc: 70.0000% - Test Loss: 0.6868 Acc: 56.6667%\n[35/50]  0m 0.0s - Train Loss: 0.5743 Acc: 70.0000% - Test Loss: 0.6721 Acc: 56.6667%\n[36/50]  0m 0.0s - Train Loss: 0.5581 Acc: 70.8333% - Test Loss: 0.6579 Acc: 60.0000%\n[37/50]  0m 0.0s - Train Loss: 0.5429 Acc: 70.8333% - Test Loss: 0.6447 Acc: 60.0000%\n[38/50]  0m 0.0s - Train Loss: 0.5286 Acc: 71.6667% - Test Loss: 0.6320 Acc: 60.0000%\n[39/50]  0m 0.0s - Train Loss: 0.5152 Acc: 72.5000% - Test Loss: 0.6202 Acc: 60.0000%\n[40/50]  0m 0.0s - Train Loss: 0.5025 Acc: 73.3333% - Test Loss: 0.6088 Acc: 60.0000%\n[41/50]  0m 0.0s - Train Loss: 0.4908 Acc: 74.1667% - Test Loss: 0.5980 Acc: 63.3333%\n[42/50]  0m 0.0s - Train Loss: 0.4798 Acc: 77.5000% - Test Loss: 0.5878 Acc: 63.3333%\n[43/50]  0m 0.0s - Train Loss: 0.4697 Acc: 79.1667% - Test Loss: 0.5779 Acc: 63.3333%\n[44/50]  0m 0.0s - Train Loss: 0.4601 Acc: 80.0000% - Test Loss: 0.5686 Acc: 66.6667%\n[45/50]  0m 0.0s - Train Loss: 0.4510 Acc: 81.6667% - Test Loss: 0.5597 Acc: 73.3333%\n[46/50]  0m 0.0s - Train Loss: 0.4425 Acc: 81.6667% - Test Loss: 0.5513 Acc: 76.6667%\n[47/50]  0m 0.0s - Train Loss: 0.4345 Acc: 82.5000% - Test Loss: 0.5431 Acc: 80.0000%\n[48/50]  0m 0.0s - Train Loss: 0.4267 Acc: 84.1667% - Test Loss: 0.5353 Acc: 80.0000%\n[49/50]  0m 0.0s - Train Loss: 0.4195 Acc: 85.8333% - Test Loss: 0.5278 Acc: 83.3333%\n[50/50]  0m 0.0s - Train Loss: 0.4129 Acc: 85.8333% - Test Loss: 0.5208 Acc: 83.3333%\nTime taken for training:  0m 0.2s\n"
    }
   ],
   "source": [
    "DATA_ROOT = 'data'\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# image datasets: {'MNIST', 'CIFAR10', 'SVHN'}\n",
    "# quantitative datasets: {'BankNote', 'BreastCancerWisconsin', 'HTRU2', 'Iris', 'WheatSeed'}\n",
    "NAME = 'Iris'\n",
    "print(f'Starting {NAME} data container...')\n",
    "print(DATASET_LIST[NAME])\n",
    "\n",
    "dc = DataContainer(DATASET_LIST[NAME], DATA_ROOT)\n",
    "dc(size_train=0.8, normalize=True)\n",
    "\n",
    "num_features = dc.dim_data[0]\n",
    "num_classes = dc.num_classes\n",
    "print('Features:', num_features)\n",
    "print('Classes:', num_classes)\n",
    "\n",
    "## model in {BCNN, IrisNN, MnistCnnCW}\n",
    "model = IrisNN(num_features, num_classes, hidden_nodes=16)  # for Iris\n",
    "model_name = model.__class__.__name__\n",
    "print('Using model:', model_name)\n",
    "\n",
    "mc = TorchModelContainer(model, dc)\n",
    "mc.fit(epochs=50, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack = FGSMContainer(mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[3.0524302 0.674838 ]\n[0. 0.]\n[0.00200009 0.00199997]\n"
    }
   ],
   "source": [
    "x1 = np.random.randn(2, 4).astype(np.float32)\n",
    "x2 = np.random.randn(2, 4).astype(np.float32)\n",
    "print(attack.get_l2_norm(x1, x2))\n",
    "print(attack.get_l2_norm(x1, x1))\n",
    "print(attack.get_l2_norm(x1, x1-1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.33333328, 0.20833333, 0.5084746 , 0.49999997],\n       [0.66666657, 0.20833333, 0.81355935, 0.7083333 ],\n       [0.5277777 , 0.3333333 , 0.6440678 , 0.7083333 ],\n       [0.5277777 , 0.5833334 , 0.7457627 , 0.9166666 ],\n       [0.5833333 , 0.5       , 0.7288136 , 0.9166666 ],\n       [0.49999994, 0.3333333 , 0.6271186 , 0.45833334],\n       [0.66666657, 0.41666666, 0.71186435, 0.9166666 ],\n       [0.02777775, 0.37500003, 0.0677966 , 0.04166667],\n       [0.02777775, 0.41666666, 0.05084745, 0.04166667],\n       [0.4166667 , 0.2916667 , 0.5254237 , 0.375     ]], dtype=float32)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attack.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('venv': venv)",
   "language": "python",
   "name": "python36964bitvenvvenv794a3f6500e74251b078ca195c3ad1e1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}